{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b31f6174",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## DUAL SVM ###################\n",
    "# \n",
    "# Primal -> the variable being optimized is w and we do it via norm minimisation for robustness and hinge loss for correctness\n",
    "# Dual   -> the unknown variable is alpha ( how much does a particular constraint resist being satisfied (to a given separator)) , \n",
    "# which constraints actually shape the separator\n",
    "#\n",
    "#\n",
    "# Geomtric view at constraints -> each constraint equation gives half-spaces ( in (w,b) space ) \n",
    "# primal was smallest norm w that lies inside all those subspaces, dual theres no assumed separator we wanna know if the intersection is non-empty\n",
    "#\n",
    "#\n",
    "# Each constraint is given a value alpha, which tells how much does this contribute to the optimum separator, support vectors ( alpha != 0) naturally come out as they refuse to relax\n",
    "#\n",
    "#\n",
    "# Lagrangian is 1/2 * || w || ** 2 - summation (alpha_i)(y_i(w*x_i +b)-1), first term penalizes sensitivity, second enforces constraints\n",
    "# Duality arrives here where we say min{w,b} max{alpha>=0} L >= max{alpha>=0}min{w,b} and we take the equal condition\n",
    "# Differentiate L wrt w -> w = summation(w_i*x_i*y_i) --> This gives another important result that optimum data can be obtained in span of given data only\n",
    "# as any component orthogonal to w increases || w ||\n",
    "# Differentiate L wrt b  get summation alpha_i*y_i=0\n",
    "#\n",
    "#\n",
    "# Substitute the w and b to get the inner product form the equation \n",
    "# KKT conditions justify our previous logical observations of behavior of alpha and constraint equations\n",
    "# \n",
    "# If data is not separable -> Primal is infeasible -> Dual objective becomes unbounded above -> Soft margin SVM prevents that only (alpha <= C)\n",
    "#\n",
    "# Updates : differentiate dual wrt alpha_k -> 1- summation alpha_i*y_i*y_k*(x_i.x_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516bf67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f31baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_dual_svm(X, Y, step_size, max_iter=20000, tol=1e-6):\n",
    "    n_features, n_samples = X.shape\n",
    "    alpha = np.zeros(n_samples)\n",
    "    K = np.dot(X.T, X)\n",
    "    H = (Y[:, None] * Y[None, :]) * K\n",
    "    cycles = 0\n",
    "    for i in range(max_iter):\n",
    "        cycles += 1\n",
    "        alpha_prev = np.copy(alpha)\n",
    "        gradient = np.ones(n_samples) - np.dot(H, alpha)\n",
    "        alpha += step_size * gradient\n",
    "        alpha = np.maximum(0, alpha)\n",
    "        if np.linalg.norm(alpha - alpha_prev) < tol:\n",
    "            break\n",
    "    w = np.dot(X, alpha * Y)\n",
    "    sv_idx = np.where(alpha > 1e-7)[0]\n",
    "    b = np.mean(Y[sv_idx] - np.dot(w, X[:, sv_idx])) if len(sv_idx) > 0 else 0.0\n",
    "    check = np.array([Y[i] * (np.dot(w, X[:, i]) + b) for i in range(n_samples)])\n",
    "    return w, b, cycles,check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b1df9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_dual_svm(X, Y, C, step_size, max_iter=20000, tol=1e-6):\n",
    "    n_features, n_samples = X.shape\n",
    "    alpha = np.zeros(n_samples)\n",
    "    K = np.dot(X.T, X)\n",
    "    H = (Y[:, None] * Y[None, :]) * K\n",
    "    cycles = 0\n",
    "    for i in range(max_iter):\n",
    "        cycles += 1\n",
    "        alpha_prev = np.copy(alpha)\n",
    "        gradient = np.ones(n_samples) - np.dot(H, alpha)\n",
    "        alpha += step_size * gradient\n",
    "        alpha = np.clip(alpha, 0, C)\n",
    "        if np.linalg.norm(alpha - alpha_prev) < tol:\n",
    "            break\n",
    "    w = np.dot(X, alpha * Y)\n",
    "    sv_idx = np.where((alpha > 1e-7) & (alpha < C))[0]\n",
    "    if len(sv_idx) == 0: sv_idx = np.where(alpha > 1e-7)[0]\n",
    "    b = np.mean(Y[sv_idx] - np.dot(w, X[:, sv_idx])) if len(sv_idx) > 0 else 0.0\n",
    "    check = np.array([Y[i] * (np.dot(w, X[:, i]) + b) for i in range(n_samples)])\n",
    "    return w, b, cycles,check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d79ddfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================= SEPARABLE: HARD SVM ====================\n",
      "Cycles : 20000 | b_h : -0.3914 | ||w_h|| : 0.7285 | Check : [0.19559144 0.33752043 0.03408301 0.23637462 0.25636014 0.21720124\n",
      " 0.11443116 0.21557696]\n",
      "w_h : [-0.40783178  0.60362626]\n",
      "\n",
      "================= SEPARABLE: SOFT SVM ====================\n",
      "Cycles : 19788 | b_s : -0.0000 | ||w_s|| : 0.2433 | Check : [-0.32609424 -0.32595289 -0.35884508 -0.33691695  1.00007068  0.93485171\n",
      "  0.99992932  1.01089339]\n",
      "w_s : [0.10822709 0.21786774]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [1.0, 1.0], [1.2, 0.9], [0.9, 1.2], [1.1, 1.0],\n",
    "    [3.0, 3.1], [2.8, 2.9], [3.2, 3.0], [3.1, 3.1]\n",
    "]).T\n",
    "Y = np.array([-1, -1, -1, -1, 1, 1, 1, 1])\n",
    "step_size = 1e-2\n",
    "\n",
    "w_h, b_h, c_h,check_h = hard_dual_svm(X, Y, step_size)\n",
    "print(\"================= SEPARABLE: HARD SVM ====================\")\n",
    "print(f\"Cycles : {c_h} | b_h : {b_h:.4f} | ||w_h|| : {np.linalg.norm(w_h):.4f} | Check : {check_h}\")\n",
    "print(f\"w_h : {w_h}\")\n",
    "\n",
    "w_s, b_s, c_s, check_s = soft_dual_svm(X, Y, 1.0, step_size)\n",
    "print(\"\\n================= SEPARABLE: SOFT SVM ====================\")\n",
    "print(f\"Cycles : {c_s} | b_s : {b_s:.4f} | ||w_s|| : {np.linalg.norm(w_s):.4f} | Check : {check_s}\")\n",
    "print(f\"w_s : {w_s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2992d08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================= OVERLAPPING: HARD SVM ====================\n",
      "Cycles : 20000 | b_h : -0.2668 | ||w_h|| : 0.4331 | Check : [ 0.12788679  0.03147024  0.21041144 -0.09111731 -0.0110322   0.12707361\n",
      "  0.09928982  0.22349016]\n",
      "w_h : [ 0.36769483 -0.22877583]\n",
      "\n",
      "================= OVERLAPPING: SOFT SVM ====================\n",
      "Cycles : 20000 | b_s : 0.0000 | ||w_s|| : 0.2311 | Check : [-0.32548289 -0.33720313 -0.34630606  0.34023744 -0.65091696  0.99413988\n",
      "  0.92905307  1.00586012]\n",
      "w_s : [0.14754548 0.17788858]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [1.0, 1.0], [1.2, 0.9], [0.9, 1.2], [1.1, 1.0],\n",
    "    [2.0, 2.0], # Conflicting outlier\n",
    "    [3.0, 3.1], [2.8, 2.9], [3.2, 3.0]\n",
    "]).T\n",
    "Y = np.array([-1, -1, -1, 1, -1, 1, 1, 1])\n",
    "step_size = 1e-3\n",
    "\n",
    "w_h, b_h, c_h,check_h = hard_dual_svm(X, Y, step_size)\n",
    "print(\"================= OVERLAPPING: HARD SVM ====================\")\n",
    "print(f\"Cycles : {c_h} | b_h : {b_h:.4f} | ||w_h|| : {np.linalg.norm(w_h):.4f} | Check : {check_h}\")\n",
    "print(f\"w_h : {w_h}\")\n",
    "\n",
    "w_s, b_s, c_s,check_s = soft_dual_svm(X, Y, 1.0, step_size)\n",
    "print(\"\\n================= OVERLAPPING: SOFT SVM ====================\")\n",
    "print(f\"Cycles : {c_s} | b_s : {b_s:.4f} | ||w_s|| : {np.linalg.norm(w_s):.4f} | Check : {check_s}\")\n",
    "print(f\"w_s : {w_s}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
